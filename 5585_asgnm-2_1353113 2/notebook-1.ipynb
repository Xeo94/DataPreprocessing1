{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Vedad Haracic\"\n",
    "STUDENTID = \"01353113\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0 (3 points)\n",
    "\n",
    "Find two data sets online (from one or several sources) that would be interesting to combine:\n",
    "\n",
    "* Each data set must have a different file format (either CSV, XML, or JSON).\n",
    "* You may start from (but you are not limited to) the resource collections hinted at in Unit 2.\n",
    "* Workable data-set sizes: The selected or extracted data sets should have thousands of entries (>= 1000), but not more than (<=) 10000 entries. If larger, use an excerpt from the original data set. Justify the extraction criteria using a Markup cell.\n",
    "* Mind the additional restrictions on data sets (no curated ones, via Open Data portal, signal adoption of the data sets to the LEARN forum).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selected datasets\n",
    "\n",
    "Data set 1: Leading Causes of Death in the US by States (format: CSV)\n",
    "\n",
    "-Creator/ authors(s) of the data set: Centers for Disease Control and Prevention\n",
    "-Names of the data repository and/or the Open Data portal used: http://www.data.gov/\n",
    "-Dataset identifier (specific to the data repository):https://catalog.data.gov/dataset/age-adjusted-death-rates-for-the-top-10-leading-causes-of-death-united-states-2013\n",
    "-Dataset publication year: December 16, 2015, Updated on: February 28, 2019\n",
    "-Last accessed (datetime of accessing, obtaining a copy of the data set): 22.03.2019\n",
    "\n",
    "Data set 2: Maryland Counties Socioeconomic Characteristics (format:JSON)\n",
    "\n",
    "-Creator/ authors(s) of the data set: opendata.maryland.gov\n",
    "-Names of the data repository and/or the Open Data portal used: http://www.data.gov/\n",
    "-Dataset identifier (specific to the data repository): https://catalog.data.gov/dataset/maryland-counties-socioeconomic-characteristics-f7e16\n",
    "-Dataset publication year: March 18, 2019\n",
    "-Last accessed (datetime of accessing, obtaining a copy of the data set): 22.03.2019\n",
    "\n",
    "\n",
    "**Project ideas**\n",
    "\n",
    "Correlation between socioeconomic status and cause of death per state in the USA. Data for the project is incomplete for now, since I don't have the socioeconomic data for all states in the USA. If my team chooses to do my idea as a project, there is a source on poverty levels and other demographic statistics on: https://www.census.gov/ .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1  (4 points)\n",
    "\n",
    "Detect the file format and file size (convert to KB or MB) of each data set, clearly documenting your actions (e.g. through commented code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File size of data/data_notebook-1_leading_cause_of_death.csv is: 789.67 KBytes (rounded on 2 decimal points)\n",
      "File size of data/data_notebook-1_maryland.json is: 95.56 KBytes (rounded on 2 decimal points)\n",
      "The format of the data/data_notebook-1_leading_cause_of_death.csv is: .csv\n",
      "The format of the data/data_notebook-1_maryland.json is: .json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#finding the data:\n",
    "filePath1=\"data/data_notebook-1_leading_cause_of_death.csv\"\n",
    "filePath2=\"data/data_notebook-1_maryland.json\"\n",
    "#declaring file size variables:\n",
    "fSize1 = os.path.getsize(filePath1)\n",
    "fSize2 = os.path.getsize(filePath2)\n",
    "#Displaying the results\n",
    "print('File size of '+filePath1+' is: '+str(round((fSize1/1024),2)) + ' KBytes (rounded on 2 decimal points)') \n",
    "print('File size of '+filePath2+' is: '+str(round((fSize2/1024),2)) + ' KBytes (rounded on 2 decimal points)') \n",
    "#detecting the file format (we can see which extension the file has and see which format it is, but here is an automated version):\n",
    "name1, ext1 = os.path.splitext(filePath1)\n",
    "name2, ext2 = os.path.splitext(filePath2)\n",
    "print(\"The format of the \"+filePath1+\" is: \"+ ext1)\n",
    "print(\"The format of the \"+filePath2+\" is: \"+ ext2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of findings\n",
    "\n",
    "**Data set 1**\n",
    "\n",
    "Format: .csv, Size: 789.67 KB, table structure.\n",
    "\n",
    "**Data set 2**\n",
    "\n",
    "Format: JSON, Size: 95.56 KB, tree structure typicall for JSON\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2  (4 points)\n",
    "\n",
    "Validate the data sets according to the data format used: Are there any data-formatting issues? Hint: You may use online validators for CSV, XML, or JSON. Pls. clearly indicate any validators used and summarize their reports."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of findings\n",
    "\n",
    "**Data set 1**\n",
    "\n",
    "Validator used: CSVLint, https://csvlint.io\n",
    "Validation results: https://csvlint.io/validation/5c98ce46aaa38a0004000056\n",
    "This file is a valid csv file according to the validator.\n",
    "You can use the validator in the last cell to validate CSV files using CSVLint API.\n",
    "\n",
    "**Data set 2**\n",
    "\n",
    "Validator used: https://jsonlint.com\n",
    "Validation result: Valid JSON\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3  (4 points)\n",
    "\n",
    "Access the two data sources and inspect their content (e.g., using the Python recipes presented to you in the notebooks and tutorials). Describe the characteristics of the data sets (depending on the format)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting the CSV file: \n",
      "---------------------------------------------------------------------\n",
      "Names of the collumns: \n",
      " Year,113 Cause Name,Cause Name,State,Deaths,Age-adjusted Death Rate\n",
      "\n",
      "Dispalying the first 10 rows: \n",
      "Year,113 Cause Name,Cause Name,State,Deaths,Age-adjusted Death Rate\n",
      "\n",
      "2016,\"Accidents (unintentional injuries) (V01-X59,Y85-Y86)\",Unintentional injuries,Alabama,2755,55.50\n",
      "\n",
      "2016,\"Accidents (unintentional injuries) (V01-X59,Y85-Y86)\",Unintentional injuries,Alaska,439,63.10\n",
      "\n",
      "2016,\"Accidents (unintentional injuries) (V01-X59,Y85-Y86)\",Unintentional injuries,Arizona,4010,54.20\n",
      "\n",
      "2016,\"Accidents (unintentional injuries) (V01-X59,Y85-Y86)\",Unintentional injuries,Arkansas,1604,51.80\n",
      "\n",
      "2016,\"Accidents (unintentional injuries) (V01-X59,Y85-Y86)\",Unintentional injuries,California,13213,32.00\n",
      "\n",
      "2016,\"Accidents (unintentional injuries) (V01-X59,Y85-Y86)\",Unintentional injuries,Colorado,2880,51.20\n",
      "\n",
      "2016,\"Accidents (unintentional injuries) (V01-X59,Y85-Y86)\",Unintentional injuries,Connecticut,1978,50.30\n",
      "\n",
      "2016,\"Accidents (unintentional injuries) (V01-X59,Y85-Y86)\",Unintentional injuries,Delaware,516,52.40\n",
      "\n",
      "This CSV file has 10297 rows.\n",
      "Number of strings: \n",
      "70206\n",
      "This csv has 70206 variables.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Inspecting the JSON file:\n",
      "---------------------------------------------------------------------\n",
      "Names of the columns:\n",
      "sid\n",
      "id\n",
      "position\n",
      "created_at\n",
      "created_meta\n",
      "updated_at\n",
      "updated_meta\n",
      "meta\n",
      "Jurisdictions\n",
      "Total Households\n",
      "Population 25 years and older\n",
      "Less than 9th Grade\n",
      "High School no Diploma\n",
      "High School Diploma\n",
      "Some College no degree\n",
      "Associates degree\n",
      "Bachelor's degree\n",
      "Graduate or Professional\n",
      "Employment Status of the Population 16 years and over\n",
      "Civilian Labor Force (16 years & over)\n",
      "Employed\n",
      "Unemployed\n",
      "Unemployment Rate\n",
      "Commute Workers 16 yrs and over\n",
      "Percent Drove Alone\n",
      "Percent Carpooled\n",
      "Percent Public Transportation\n",
      "Percent Walked\n",
      "Percent Other\n",
      "Percent Worked at Home\n",
      "Median Household Income ($)\n",
      "Families\n",
      "Percent Families in Poverty\n",
      "Percent Civilian Population w/ Health Ins. Cov.\n",
      "Total Housing Units\n",
      "Percent Occupied\n",
      "Percent Vacant\n",
      "Total Population\n",
      "Voting Age Population\n",
      "Male\n",
      "Female\n",
      "White Alone\n",
      "Black Alone\n",
      "Asian Alone\n",
      "American Indian/Alaska Native Alone\n",
      "Native Hawaiian/Pacific Islander Alone\n",
      "Some Other Race Alone\n",
      "Two or More Races\n",
      "Hispanic or Latino (of any race)\n",
      "---------------------------------------------------------------------\n",
      "Column: sid--------> Value: 24\n",
      "Column: id--------> Value: 3987AFF0-6609-4757-B796-793B14E105CA\n",
      "Column: position--------> Value: 24\n",
      "Column: created_at--------> Value: 1519141552\n",
      "Column: created_meta--------> Value: 697395\n",
      "Column: updated_at--------> Value: 1519141552\n",
      "Column: updated_meta--------> Value: 697395\n",
      "Column: meta--------> Value: None\n",
      "Column: Jurisdictions--------> Value: Baltimore city\n",
      "Column: Total Households--------> Value: 242416\n",
      "Column: Population 25 years and older--------> Value: 422021\n",
      "Column: Less than 9th Grade--------> Value: 21605\n",
      "Column: High School no Diploma--------> Value: 48234\n",
      "Column: High School Diploma--------> Value: 124847\n",
      "Column: Some College no degree--------> Value: 82268\n",
      "Column: Associates degree--------> Value: 19644\n",
      "Column: Bachelor's degree--------> Value: 66163\n",
      "Column: Graduate or Professional--------> Value: 59260\n",
      "Column: Employment Status of the Population 16 years and over--------> Value: 502739\n",
      "Column: Civilian Labor Force (16 years & over)--------> Value: 310323\n",
      "Column: Employed--------> Value: 274906\n",
      "Column: Unemployed--------> Value: 35417\n",
      "Column: Unemployment Rate--------> Value: 11.4\n",
      "Column: Commute Workers 16 yrs and over--------> Value: 270104\n",
      "Column: Percent Drove Alone--------> Value: 59.8\n",
      "Column: Percent Carpooled--------> Value: 9.2\n",
      "Column: Percent Public Transportation--------> Value: 18.4\n",
      "Column: Percent Walked--------> Value: 6.7\n",
      "Column: Percent Other--------> Value: 2.2\n",
      "Column: Percent Worked at Home--------> Value: 3.7\n",
      "Column: Median Household Income ($)--------> Value: 44262\n",
      "Column: Families--------> Value: 124615\n",
      "Column: Percent Families in Poverty--------> Value: 18.3\n",
      "Column: Percent Civilian Population w/ Health Ins. Cov.--------> Value: 91.0\n",
      "Column: Total Housing Units--------> Value: 296923\n",
      "Column: Percent Occupied--------> Value: 81.6\n",
      "Column: Percent Vacant--------> Value: 18.4\n",
      "Column: Total Population--------> Value: 621000\n",
      "Column: Voting Age Population--------> Value: 462193\n",
      "Column: Male--------> Value: 292168\n",
      "Column: Female--------> Value: 328832\n",
      "Column: White Alone--------> Value: 187894\n",
      "Column: Black Alone--------> Value: 391160\n",
      "Column: Asian Alone--------> Value: 15712\n",
      "Column: American Indian/Alaska Native Alone--------> Value: 1799\n",
      "Column: Native Hawaiian/Pacific Islander Alone--------> Value: 342\n",
      "Column: Some Other Race Alone--------> Value: 10065\n",
      "Column: Two or More Races--------> Value: 14028\n",
      "Column: Hispanic or Latino (of any race)--------> Value: 29537\n",
      "---------------------------------------------------------------------\n",
      "The number of type String in the observation:44\n",
      "The number of type int in the observation:4\n",
      "Number of None types across the observations:24\n",
      "Number of variables across the observations:1176\n",
      "Number of columns per observation: 49\n"
     ]
    }
   ],
   "source": [
    "print(\"Inspecting the CSV file: \")\n",
    "print(\"---------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "#creating an empty list where rows will be stored\n",
    "liste=[]\n",
    "#opening the csv file:\n",
    "with open ('./data/data_notebook-1_leading_cause_of_death.csv','r') as f:\n",
    "    rows=f.readlines()\n",
    "    print(\"Names of the collumns: \\n \"+rows[0])\n",
    "    #creating a variable which counts the number of rows:\n",
    "    counter=0\n",
    "    print(\"Dispalying the first 10 rows: \")\n",
    "    for row in rows:\n",
    "        counter+=1\n",
    "        liste.append(row.strip().split(','))\n",
    "        if counter<10:\n",
    "            print(row)\n",
    "            \n",
    "        \n",
    "    print(\"This CSV file has \"+str(counter)+\" rows.\")\n",
    "variable_counter=0\n",
    "string_counter=0\n",
    "for i in liste:\n",
    "    for j in i:\n",
    "        variable_counter+=1\n",
    "        if type(j)== str:\n",
    "            string_counter+=1\n",
    "\n",
    "print(\"Number of strings: \")            \n",
    "print(string_counter)        \n",
    "print(\"This csv has \"+ str(variable_counter)+\" variables.\")\n",
    "\n",
    "#Now I am going to inspect the JSON file:\n",
    "print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "print(\"Inspecting the JSON file:\")\n",
    "print(\"---------------------------------------------------------------------\")\n",
    "\n",
    "import json\n",
    "with open (\"./data/data_notebook-1_maryland.json\",\"rb\") as file:\n",
    "    data=json.load(file)\n",
    "    info=data['meta']['view']['description']\n",
    "    column_names=[]\n",
    "    for name in data['meta']['view']['columns']:\n",
    "        #print(name['name'])\n",
    "        column_names.append(name['name'])\n",
    "print(\"Names of the columns:\")\n",
    "for i in column_names:\n",
    "    print(i)\n",
    "#Now I am going to explore the data inside:\n",
    "json_data=[]\n",
    "for j in data['data']:\n",
    "    json_data.append(j)\n",
    "json_dict={}\n",
    "for i in json_data:\n",
    "    \n",
    "    json_dict=dict(zip(column_names,i))\n",
    "print(\"---------------------------------------------------------------------\")\n",
    "Json_column_counter=0\n",
    "#Displaying the 24th observation:\n",
    "for k in json_dict:\n",
    "    print(\"Column: \"+str(k)+\"--------> Value: \"+str(json_dict[k]))\n",
    "    Json_column_counter+=1\n",
    "        \n",
    "print(\"---------------------------------------------------------------------\")\n",
    "#Now I am going to count the variable type in the observation:\n",
    "int_count=0\n",
    "str_count=0\n",
    "number_of_observations=0\n",
    "none_counter=0\n",
    "number_of_variables=0\n",
    "for k in json_data:\n",
    "    int_count=sum(isinstance(v, int) for v in k)\n",
    "    str_count=sum(isinstance(v, str) for v in k)\n",
    "    for v in k:\n",
    "        number_of_variables+=1\n",
    "        if v is None:\n",
    "            none_counter+=1\n",
    "    number_of_observations+=1\n",
    "print(\"The number of type String in the observation:\"+str(str_count))\n",
    "print(\"The number of type int in the observation:\"+str(int_count))\n",
    "print(\"Number of None types across the observations:\"+str(none_counter))\n",
    "print(\"Number of variables across the observations:\"+str(number_of_variables))\n",
    "print(\"Number of columns per observation: \"+str(Json_column_counter))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of findings\n",
    "\n",
    "**Data set 1**\n",
    "\n",
    "Data set data_notebook-1_leading_cause_of_death.csv has 70206 variables across 10297 rows. These variables are all of type String.\n",
    "\n",
    "**Data set 2**\n",
    "Data set data_notebook-1_maryland.json\n",
    "Print statements above show the collumn names, the number of string, int, and none types.\n",
    "\n",
    "This JSON has multiple nestings:\n",
    "meta{metadata is shown here, all column names and other information about this JSON is stored here}\n",
    "data{24 observations in lists (just values)}\n",
    "This JSON file has a small ammount of observations, but this is due to the number of counties in Maryland. \n",
    "In this file there are 1176 variables, many belonging to metadata. There are 24 observations in this file with 49 variables each.\n",
    "\n",
    "This might seem small, but I could not find any datasets with data from all US states (there is a way to download them from the US Census Office, but they are in an excel format and have to be downloaded seperately for each year). When opened in text editor, this file has about 3500 lines. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus work  (up to 4 points)\n",
    "\n",
    "Automate the data-set validation (as described in Step 2) using a Python code fragment, for *one* data set. Use the single code cell below and comment your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'version': '0.1', 'licence': 'http://opendatacommons.org/licenses/odbl/', 'package': {'validations': []}}\n"
     ]
    }
   ],
   "source": [
    "# I am not sure if this work is being graded, but I will do it anyway, since I did not do this part in my homework from the previous semester\n",
    "#Importing requests module for web requests\n",
    "import requests\n",
    "# Importing time module to delay the response (this is required according to API documentation)\n",
    "import time\n",
    "def CSVChecker(x):\n",
    "    data = {\n",
    "  'urls[]': x}\n",
    "    user_agent = 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.103 Safari/537.36'\n",
    "    header={'User-Agent' : user_agent }\n",
    "    #posting a file:\n",
    "    request = requests.post('http://csvlint.io/package.json', data=data,headers=header)\n",
    "    first=request.json()\n",
    "    #getting the url for the verification results\n",
    "    csvid=first['package']['url']+'.json'\n",
    "    time.sleep(5)\n",
    "    #getting the validation results and returning them:\n",
    "    response=requests.get(csvid)\n",
    "    result=response.json()\n",
    "    return result\n",
    "print(CSVChecker(\"https://catalog.data.gov/dataset/age-adjusted-death-rates-for-the-top-10-leading-causes-of-death-united-states-2013\"))\n",
    "#Somethimes CSVLint wont return the complete validation JSON file, if that happens, just run the cell again.\n",
    "#CSVLint is still in testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
